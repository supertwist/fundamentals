*Note: this glossary was generated by ChatGPT 4o! (with some editing and commentary from James H.)*
*Trust it ONLY as far as you can throw it.*

*Notes to students: I created this as an exercise to see how useful ChatGPT might be...*
*While the content generated may be factually incorrect, it can spur trains of thought.*
*Ride those rails as far as you can.*
*Another insight: ChatGPT is useful for generating concrete examples of abstractions.*

*This document will evolve, and I will check against non-AI souces as time allows.*

# A
**Alignment** - Ensuring a model’s behavior aligns with human intentions and ethical guidelines, critical in safe AI deployment. Here are three examples of alignment in generative AI:
1.	Content Moderation for Safe Responses: Alignment techniques are applied to ensure that a generative AI model avoids harmful or offensive content. For example, if asked a provocative question, an aligned AI model will respond in a neutral or informative way, steering clear of inappropriate or inflammatory responses.
2.	Values-Based Responses in Education Tools: An aligned AI used for educational purposes might be trained to encourage curiosity, empathy, and inclusivity in its responses. For example, if a student asks a sensitive question, the AI could respond in a supportive, respectful manner that aligns with educational values and promotes a positive learning environment.
3.	User-Specific Personalization and Assistance: When aligned with user goals, a generative AI assistant adapts its responses to the user’s specific needs. For instance, if a user seeks health advice, the model provides balanced, evidence-based information aligned with reputable health guidelines, ensuring advice is safe, relevant, and responsible.

**Artificial Intelligence (AI)** - The simulation of human intelligence in machines that can perform tasks typically requiring human intelligence, such as visual perception, speech recognition, decision-making, and language translation.

**Attention Mechanism** - A technique used in neural networks to focus on certain parts of an input sequence, especially useful in sequence-to-sequence tasks. (See Transformer.)

# B
**Bias** - Systematic errors or unfair advantages/disadvantages learned by a model, often due to unbalanced or incomplete training data. Here are three examples of bias in generative AI:
1.	Cultural and Gender Stereotypes: Generative language models trained on internet data can produce stereotypical descriptions or responses. For instance, when prompted with certain professions, the model might assume a specific gender, reinforcing cultural stereotypes (e.g., associating “nurse” with women or “engineer” with men).
2.	Underrepresentation of Minority Groups: Models trained on imbalanced datasets may produce content that reflects a narrow demographic focus, often favoring majority groups. For example, an image generation model trained mostly on Western faces might struggle to generate accurate images of people from diverse ethnic backgrounds, leading to underrepresentation or misrepresentation of minority groups.
3.	Political or Ideological Bias: Language models can inherit biases from training data that include dominant political or ideological perspectives. As a result, they may generate content that subtly or overtly favors certain viewpoints over others, potentially skewing information and creating echo chambers when used in news or opinion-based applications.

**Bias Mitigation** - Techniques used to reduce or eliminate biases within a model, often crucial for generative AI. Here are three examples of bias mitigation in generative AI:
1.	Balanced Training Data: To reduce biases, AI developers can create or curate training datasets that include diverse and representative examples from various demographics, cultures, and viewpoints. This approach helps ensure the model learns a more balanced perspective and minimizes the risk of favoring any single group or viewpoint.
2.	Adversarial Debiasing: This technique uses an additional model (or adversarial network) to detect and penalize biased patterns during training. By iteratively training the generative model to produce outputs that are evaluated for fairness by the adversarial model, the AI learns to reduce biased responses.
3.	Post-Processing Bias Filters: After generating content, the AI’s output can be analyzed using bias detection tools or filters that flag potentially biased or harmful responses. These filters can either modify or reject biased outputs, ensuring that the final result aligns with fairness and inclusivity standards.

# C
**Context Window** - The context window in generative AI refers to the maximum amount of text or data that a model can process at once when generating or analyzing content. Essentially, it defines how much information the model can “see” in a single pass, which affects its ability to understand and produce coherent responses based on previous parts of the text. For instance, if a model has a context window of 4,000 tokens, it can only consider the last 4,000 tokens as context for any response. A smaller context window limits the model’s ability to maintain consistency over long pieces of text, while a larger context window allows it to handle complex, multi-turn dialogues or lengthy documents without losing track of relevant details. Increasing the context window enhances the model’s performance on tasks requiring extensive contextual understanding, such as summarizing long articles or engaging in extended conversations.

The context window size and the prompt size are related but not the same. The context window size is the maximum amount of tokens (words, subwords, or characters) that the model can consider at once, including both the prompt (input from the user) and any generated output within a single interaction.

The prompt size, on the other hand, refers specifically to the portion of the context window taken up by the input text or instructions provided by the user. For example, if a model has a context window of 8,192 tokens and a prompt uses 3,000 tokens, then the model has 5,192 tokens left for generating responses. When the prompt and responses exceed the context window limit, the oldest parts of the conversation are typically removed or “forgotten” to make room for new content.

*Note: I asked ChatGPT 4o what its prompt size is... it could not disclose!*

# D
**Data Augmentation** - Techniques for increasing the diversity of a training dataset by modifying data in various ways, such as flipping images or altering text.

**Decoder** - Part of a neural network, typically in sequence-to-sequence models, that generates output from encoded data. See Transformer.

**Deep Learning** - A subset of ML using neural networks with many layers (deep neural networks) to model complex patterns in large datasets.

**Diffusion Model** - A type of generative model that learns to reverse a noise process to generate new data, often used for image synthesis.

# E
**Embedding** - The representation of words, sentences, or other data types as vectors, enabling a model to process text in numerical form.

**Encoder** - An encoder in neural networks is a component that processes input data and transforms it into a compact, encoded representation. By extracting essential features and reducing dimensionality, the encoder makes it easier for the model to understand and process complex information, especially for tasks like classification, translation, and data compression.

**Ethics in AI** - Considerations around the societal, moral, and legal implications of deploying AI, especially generative models. ere are three examples of ethical issues in generative AI:
1.	Misinformation and Deepfakes: Generative AI can create hyper-realistic fake images, videos, or audio, often indistinguishable from real content. This can lead to misinformation or harm individuals’ reputations, especially when used maliciously to spread false information or fabricate events.
2.	Bias and Fairness: Generative AI models can learn biases present in their training data, leading to unfair or harmful outputs. For instance, a model trained on biased data might reinforce stereotypes or make discriminatory decisions in applications like hiring, law enforcement, or media representation.
3.	Intellectual Property and Copyright: Generative AI can create new content that resembles copyrighted material, raising questions about originality and ownership. This issue is significant for artists and content creators whose work may be replicated or imitated without credit or compensation.

# F
**Few-Shot Learning** - Training a model on a task with only a few examples, often seen in generative models that perform well with limited data.

**Fine-tuning** - The process of adjusting a pre-trained model on a smaller, task-specific dataset to improve its performance on that task.

# G
**Generative Adversarial Network (GAN)** - A generative model framework with two neural networks (generator and discriminator) competing in a zero-sum game to improve data generation.

**Generative Model** - A type of model that learns to generate new data that resembles a training dataset, commonly used in creating images, text, audio, or video.

**Gradient Descent** - An optimization algorithm used to minimize a model’s error by iteratively adjusting weights in the neural network.

**GPT (Generative Pre-trained Transformer)** - A type of LLM developed by OpenAI that generates text by predicting subsequent words based on context.

# H
**Hallucination** - When a generative model produces false or misleading information confidently, despite lacking factual basis.

**Hyperparameters** - Configurable settings that control the model training process, such as learning rate, batch size, and number of layers.

# I
**Inpainting** - A technique where a model fills in missing parts of an image or text based on surrounding content. (see Outpainting)

Inpainting remains coherent with the rest of the image by using contextual information from surrounding pixels to generate new content that blends seamlessly with existing elements. During inpainting, the model analyzes the textures, colors, shapes, and edges in the areas adjacent to the missing or masked region. By learning these patterns, the model can predict and generate details that fit naturally into the scene, maintaining visual continuity. Advanced inpainting models, like those based on diffusion or GANs, are specifically trained to understand context and recognize common patterns within an image, enabling them to produce realistic and coherent extensions that align with the original style and content of the image.

# L
**Large Language Model (LLM)** - A model trained on vast amounts of text data, enabling it to generate human-like language and understand context. Examples include GPT, BERT, and T5.

**Latent Space** - A representation space where a model encodes input data, allowing relationships and patterns to be mapped in lower dimensions.

# M
**Machine Learning (ML)** - A subset of AI focused on using algorithms and statistical models to enable computers to perform specific tasks without explicit programming by learning from data.

**Multimodal Model** - A model that can process and generate multiple types of data, such as text and images, often simultaneously.

# N
**Natural Language Processing (NLP)** - A field of AI focused on the interaction between computers and human language, enabling tasks like language translation, text generation, and sentiment analysis.

**Neural Network** - A model inspired by the human brain’s network of neurons, consisting of layers of nodes (neurons) that can process and recognize patterns in data.

**Node** - In neural networks, nodes (or neurons) correspond to units in each layer that process input data, while parameters include the weights and biases that control each node’s behavior. Each connection between nodes has an associated weight parameter, which determines the strength and direction of the connection’s influence on the next layer. Additionally, each node often has a bias parameter that shifts its output, providing flexibility in how each node processes information.

Together, weights and biases are the adjustable parameters learned during training. They define how data flows through the network, and their values are iteratively optimized to minimize error, allowing the network to recognize patterns and make accurate predictions.

A single node (or neuron) in a neural network typically has one bias parameter and multiple weights—one weight for each connection to nodes in the previous layer. So, if a node receives inputs from  n  nodes in the previous layer, it will have:
	•	 n  weight parameters (one for each input connection)
	•	1 bias parameter

In total, a node will have  n + 1  parameters. For example, if there are 5 connections from the previous layer to this node, it will have 5 weights and 1 bias, totaling 6 parameters.

**Noise** - In the context of diffusion models, noise refers to random disturbances added to an image or data sample in a step-by-step process, effectively degrading it until it becomes nearly unrecognizable. During training, the model learns to reverse this “diffusion” of noise, predicting and reconstructing each previous step to gradually generate coherent data from pure noise. By learning this process, the model becomes capable of generating new, high-quality images or data by reversing the noise addition process from a random starting point.

# 0

**Outpainting** - A technique in generative AI that extends an image beyond its original borders by generating new, visually coherent content that blends seamlessly with the existing image. This process uses context from the original image to imagine and fill in surrounding areas, allowing for creative expansion and completion of visual scenes. (see Inpainting)

**Overfitting** - Overfitting occurs when a model learns the training data too well, capturing not only the underlying patterns but also the noise and outliers specific to that dataset. While this might make the model perform exceptionally well on training data, it often leads to poor performance on new, unseen data because the model struggles to generalize beyond the exact examples it has learned. In essence, an overfitted model becomes too specialized, lacking the flexibility needed to adapt to variations in real-world data. To mitigate overfitting, techniques such as regularization, dropout, early stopping, and using larger, more varied datasets are employed, helping the model to focus on general patterns rather than memorizing specifics.

# P
**Parameter** - (see Node.)

**Personalization** - Adjusting a model’s outputs to suit individual users’ preferences or characteristics, enhancing user experience.

**Positional Encoding** - (see Transformer.)

**Pre-training** - The process of training a model on a large dataset in an unsupervised manner before fine-tuning on a specific task.

**Prompt** - An initial input or question used to instruct or guide a generative AI model to produce specific outputs.

# R
**Reinforcement Learning from Human Feedback (RLHF)** - A training method that incorporates human preferences to improve model responses.

# S
**Sampling** - The process of generating new data points by selecting from a probability distribution produced by a generative model.

**Seed** - In generative AI, a seed is an initial input value used to set or control the randomness of the model’s output. Seeds ensure reproducibility, meaning that if the same model, prompt, and seed are used, the model will produce identical results each time. This is particularly useful in creative tasks, such as image generation or story generation, where consistency might be desired across multiple runs. By changing the seed, users can influence the model to generate different variations, allowing exploration of diverse outputs from the same input prompt. In essence, the seed acts as a starting point for random sampling, enabling both controlled experimentation and creative variability in AI-generated content.

*Using the same seed, but altering other parameters by increments, is a useful method for uderstanding the impact of changes in other parameters.*

**Self-Attention** - A mechanism where each part of an input sequence interacts with all other parts to understand dependencies, used widely in transformers. (see Transformer.)

# T
**Temperature** - In the context of generative AI, temperature is a parameter that controls the randomness and creativity of the model’s responses. Lower temperature values (close to 0) make the model more deterministic and focused, often leading to precise and conservative outputs as it favors the most probable or predictable choices. Higher temperature values (approaching 1 or above) introduce more randomness, enabling the model to explore a wider range of possible words or phrases, which can lead to more creative, varied, or unexpected responses. For example, a higher temperature might be used for tasks requiring originality, like storytelling, while a lower temperature might be preferred for factual tasks, like answering technical questions. Adjusting temperature helps tailor the model’s behavior to suit different use cases, balancing between coherence and creativity.

**Token** - A token is a unit of data, such as a word, subword, or character, that a model processes individually. In natural language processing, tokens are created by breaking down text into smaller, manageable parts, enabling the model to analyze and generate language effectively. Tokenization converts text into a sequence of tokens, each with a unique identifier, allowing the model to understand and work with language systematically.

**Tokenization** - The process of splitting text into smaller units, or tokens, for a model to process.

Audio data is tokenized by breaking down the audio waveform into small, manageable segments or features that can be processed by a model. This often involves:
1.	Segmenting the Audio: The continuous audio signal is split into short, fixed-length time frames (typically a few milliseconds each), capturing local patterns and fluctuations in sound.
2.	Extracting Features: For each frame, features like Mel-frequency cepstral coefficients (MFCCs), spectrogram values, or log-Mel spectrograms are extracted. These features represent the audio’s frequency and intensity over time, creating a structured, numerical representation that retains meaningful information.
3.	Encoding as Tokens: Each frame or feature vector becomes a “token” that the model processes sequentially, similar to how text is tokenized into words or subwords.

This approach allows models to understand patterns in audio, such as phonemes in speech, which can then be used for tasks like speech recognition, synthesis, or classification.

Images are tokenized by dividing them into smaller, structured units that a model can process in sequence. Common methods include:
1.	Dividing into Patches: The image is split into small, fixed-size patches (e.g., 16x16 pixels), treating each patch as a single token. This approach is used in models like Vision Transformers (ViTs), where each patch represents a distinct part of the image and is embedded as a vector.
2.	Flattening Pixels or Using Grids: In some cases, each pixel or a grid of pixels is treated as an individual token, especially for detailed image analysis. Each pixel or grid region’s RGB or grayscale values form a feature vector, creating a structured representation.
3.	Applying Feature Extraction: Convolutional neural networks (CNNs) or other feature extractors can convert image regions into high-level feature vectors, which can be tokenized as representations of shapes, textures, or edges.

Tokenizing images in this way allows models to process visual information systematically, enabling tasks like image recognition, segmentation, and generation by understanding patterns within and between image regions.

**Training** (in Generative AI) is the process of teaching a model to generate new data by learning patterns and features from a given dataset. During training, the model processes input data, adjusts its internal parameters, and minimizes error using optimization techniques (like gradient descent) to improve its ability to recreate or extend patterns in the data. This involves feeding the model large datasets and iterating over them multiple times so it can learn underlying structures and relationships. The result is a model that can generate new, similar data, whether it’s images, text, or other forms of content, based on the learned patterns.

Here are some best practices for gathering high-quality training data for machine learning models:
1.	Ensure Diversity and Representativeness: Include a wide range of examples that represent all relevant demographics, use cases, and scenarios to prevent biases and enhance model generalization. For example, if training a language model, gather data from various sources, dialects, and languages to capture diverse linguistic patterns.
2.	Data Quality and Accuracy: Use reliable sources and verify the accuracy of your data to ensure the model learns correct information. Avoid using noisy or poorly labeled data, as this can degrade model performance. Cleaning and preprocessing data to remove inconsistencies, duplicates, and errors are essential steps.
3.	Ethical and Privacy Compliance: Adhere to ethical guidelines and legal standards (e.g., GDPR) when collecting data, especially if it includes personal or sensitive information. Anonymize and secure data wherever possible to protect individual privacy.
4.	Balance Across Categories: Strive for balanced data across relevant categories to prevent the model from being skewed toward overrepresented groups. For example, in a sentiment analysis model, ensure equal representation of positive, neutral, and negative sentiments to avoid a bias in predictions.
5.	Labeling Consistency: Use consistent and accurate labeling practices, ideally with multiple labelers for quality assurance. Implement a standardized guideline for labelers to minimize subjectivity and discrepancies.
6.	Use Real-World Data: When possible, gather data that closely resembles the scenarios in which the model will be used. This will help the model learn relevant patterns and perform effectively in practical applications.
7.	Maintain Transparency and Documentation: Document the data collection process, including the sources, any preprocessing steps, and the rationale behind the selection criteria. This transparency aids in understanding any limitations or biases in the data and allows for informed adjustments later.
8.	Data Augmentation: To increase dataset diversity and quantity, consider data augmentation techniques, such as generating slight variations in the data (e.g., flipping images, paraphrasing sentences) to improve model robustness without collecting entirely new data.

**Transformer** - Transformers are a type of neural network architecture that excels at processing sequential data, like text, by focusing on relationships within the data rather than processing it one step at a time, as recurrent neural networks (RNNs) do. Developed in 2017 by researchers at Google Brain, the transformer architecture introduced a breakthrough in handling long-range dependencies and understanding context, making it foundational for many modern language models, including BERT, GPT, and T5.

Here’s a breakdown of the key concepts and processes that make transformers work:

Self-Attention Mechanism - Central to the transformer is the self-attention mechanism, which allows each word (or token) in a sequence to “pay attention” to every other word, weighing their importance relative to the current word. This is crucial because it helps the model understand context more accurately. For example, in the sentence “The cat sat on the mat, and it was soft,” the self-attention mechanism helps the model understand that “it” refers to “the mat,” not “the cat.” Self-attention calculates three vectors for each word: Query, Key, and Value. By calculating the similarity between the Query of one word and the Key of another, the model determines how much attention to give to other words and produces a weighted sum of their Values. This weighted sum helps the model grasp relationships and dependencies in the data.

Positional Encoding - Transformers don’t process tokens sequentially. To help the model understand the order of words (important for natural language understanding), transformers use positional encoding. Positional encodings are added to each token’s embedding, so the model knows whether a word appears first, last, or somewhere in between in a sequence. Positional encodings allow transformers to make sense of word order even without traditional sequence-based processing, making them more effective at capturing global context.

Multi-Head Attention - Self-attention in transformers is divided into multiple attention heads (multi-head attention). Each head performs its own self-attention calculation on the input sequence, allowing the model to focus on different aspects of the sequence in parallel. For instance, one head might focus on relationships related to subject-verb agreement, while another might focus on object relationships. By combining the outputs from each head, the transformer gains a richer understanding of context and relationships across the sequence.

Encoder-Decoder Structure - The transformer model is structured in layers, with each layer containing both self-attention and feed-forward neural networks. It is typically divided into encoder and decoder components: The encoder layers process the input data, learning internal representations that capture the input sequence’s contextual meanings. The decoder layers generate output sequences (e.g., a translation or response) based on the encoder’s output. Each decoder layer also includes attention mechanisms that allow it to focus on relevant parts of the encoded input sequence. For tasks like translation or summarization, the encoder processes the input sentence while the decoder generates the output sentence, one token at a time.

Feed-Forward Networks and Layer Normalization - Each transformer layer also contains a feed-forward neural network applied to each token individually and identically. This network further processes the token representations learned by self-attention. To help the network train efficiently, transformers use layer normalization after each attention and feed-forward sub-layer, normalizing outputs to make learning more stable and prevent issues from exploding or vanishing gradients.

Parallelization and Scalability - Unlike RNNs that process sequences step-by-step, transformers process the entire sequence simultaneously, making them highly parallelizable and more computationally efficient. This enables them to scale well on powerful hardware like GPUs and TPUs. This parallelism allows transformers to handle much longer input sequences than previous models, significantly boosting performance on long-text understanding, generation, and summarization.

Training and Transfer Learning - Transformers are typically trained on massive datasets in an unsupervised manner, using techniques like masked language modeling (e.g., BERT) or autoregressive training (e.g., GPT). After this pre-training, transformers can be fine-tuned on smaller, task-specific datasets for applications like question answering, translation, or chatbots. This transfer learning capability makes transformers highly versatile.

Transformers have become foundational in natural language processing (NLP), powering applications like:
* Language Translation (e.g., Google Translate uses transformer models for accurate translations),
* Text Summarization (transformers can condense information from long documents),
* Question Answering (by understanding context to answer questions accurately),
* Text Generation (generating coherent, contextually relevant responses in chatbots and virtual assistants).

Transformers revolutionized how we handle sequential data, especially text, by focusing on attention mechanisms over traditional sequence-based processing. This design has led to significant advancements in generative AI, enabling models that produce increasingly realistic and contextually relevant outputs.

# V
**Variational Autoencoder (VAE)** - A generative model that encodes data to a lower-dimensional space and decodes it, allowing the generation of new data instances that resemble the training data.

# Z
**Zero-Shot Learning** - When a model performs a task without being explicitly trained on it by leveraging general understanding from diverse training data.
